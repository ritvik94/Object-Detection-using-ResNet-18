import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import os
import time
import numpy as np
import matplotlib.pyplot as plt # For plotting
import seaborn as sns           # For confusion matrix visualization
from sklearn.metrics import confusion_matrix
import random # For selecting random samples for visualization

# --- Data Preparation ---
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomCrop(32, padding=4),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

print("Downloading CIFAR-10 datasets...")
train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)
print("CIFAR-10 datasets downloaded.")

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)

# CIFAR-10 class names for visualization
cifar10_class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# --- Model Definition (ResNet) ---
class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion * planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion * planes)
            )
        self.skip_add = nn.quantized.FloatFunctional()
        self.relu_add = nn.ReLU(inplace=True)

    def forward(self, x):
        identity = x
        out = self.relu1(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out = self.skip_add.add(out, self.shortcut(identity))
        out = self.relu_add(out)
        return out

class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_planes = 64
        self.quant = torch.quantization.QuantStub() 
        self.dequant = torch.quantization.DeQuantStub()

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)
        self.dropout = nn.Dropout(0.3)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride_val in strides:
            layers.append(block(self.in_planes, planes, stride_val))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        # QuantStub/DeQuantStub are placeholders for QAT, not active in FP32 training
        x = self.quant(x) # These are essentially no-ops during FP32 training
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.avgpool(out)
        out = out.view(out.size(0), -1)
        out = self.dropout(out)
        out = self.fc(out)
        out = self.dequant(out) # These are essentially no-ops during FP32 training
        return out

def ResNet18():
    return ResNet(BasicBlock, [2, 2, 2, 2])

# --- Training and Evaluation Functions ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

def train_epoch(model, train_loader, criterion, optimizer, scaler, current_device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(current_device, non_blocking=True), target.to(current_device, non_blocking=True)
        optimizer.zero_grad()

        # Always use autocast for FP32 training on CUDA for performance
        if current_device == torch.device('cuda'):
            with torch.amp.autocast('cuda'):
                output = model(data)
                loss = criterion(output, target)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else: # CPU training
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

        running_loss += loss.item()
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()

    return running_loss / len(train_loader), 100. * correct / total

def test_epoch(model, test_loader, criterion, current_device):
    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(current_device, non_blocking=True), target.to(current_device, non_blocking=True)

            if current_device == torch.device('cuda'):
                with torch.amp.autocast('cuda'): # Use autocast for FP32 inference on CUDA
                    output = model(data)
            else:
                output = model(data)

            loss = criterion(output, target)

            test_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())

    return test_loss / len(test_loader), 100. * correct / total, all_preds, all_targets

def train_model(model_instance, num_epochs, target_accuracy, model_type,
                optimizer_instance, scheduler_instance, scaler_instance, current_device):
    print(f"Starting optimized training for {num_epochs} epochs ({model_type} model)...")
    print(f"Target accuracy: {target_accuracy}%")
    print(f"Model parameters: {sum(p.numel() for p in model_instance.parameters() if p.requires_grad):,}")

    best_acc = 0.0
    patience = 15
    patience_counter = 0

    train_losses_history = []
    train_accs_history = []
    test_losses_history = []
    test_accs_history = []

    for epoch in range(num_epochs):
        train_loss, train_acc = train_epoch(model_instance, train_loader, criterion,
                                             optimizer_instance, scaler_instance, current_device)
        # We'll get them after loading the best model.
        test_loss, test_acc, _, _ = test_epoch(model_instance, test_loader, criterion, current_device)
        scheduler_instance.step()

        train_losses_history.append(train_loss)
        train_accs_history.append(train_acc)
        test_losses_history.append(test_loss)
        test_accs_history.append(test_acc)

        if test_acc > best_acc:
            best_acc = test_acc
            patience_counter = 0
            torch.save(model_instance.state_dict(), 'best_float_model.pth')
        else:
            patience_counter += 1

        current_lr = optimizer_instance.param_groups[0]['lr']
        print(f"Epoch {epoch+1:2d}/{num_epochs}: "
              f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:5.2f}% | "
              f"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:5.2f}% | "
              f"Best: {best_acc:.2f}% | LR: {current_lr:.6f}")

        if best_acc >= target_accuracy:
            print(f"Target accuracy {target_accuracy}% reached! Stopping early.")
            break
        if patience_counter >= patience:
            print(f"Early stopping: No improvement for {patience} epochs.")
            break
    return best_acc, train_losses_history, train_accs_history, test_losses_history, test_accs_history

def measure_model_size(model, filename="temp_model.pth"):
    torch.save(model.state_dict(), filename)
    size_mb = os.path.getsize(filename) / (1024 * 1024)
    os.remove(filename)
    return size_mb

def measure_inference_time(model, test_loader, current_device, num_warmup_batches=5, num_measure_batches=50):
    model.eval()
    model.to(current_device)
    for i, (data, _) in enumerate(test_loader):
        if i >= num_warmup_batches: break
        data = data.to(current_device)
        if current_device == torch.device('cuda'):
             with torch.amp.autocast('cuda'): 
                 _ = model(data)
        else:
            _ = model(data)

    timings = []
    with torch.no_grad():
        for i, (data, _) in enumerate(test_loader):
            if i >= num_measure_batches: break
            data = data.to(current_device)
            if current_device == torch.device('cuda'):
                starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
                starter.record()
                with torch.amp.autocast('cuda'):
                    _ = model(data)
                ender.record()
                torch.cuda.synchronize()
                timings.append(starter.elapsed_time(ender))
            else:
                start_time = time.perf_counter()
                _ = model(data)
                end_time = time.perf_counter()
                timings.append((end_time - start_time) * 1000)

    mean_time_per_batch = np.mean(timings)
    avg_inference_time_ms = mean_time_per_batch / test_loader.batch_size
    return avg_inference_time_ms


# --- Visualization Functions ---

def plot_metrics(train_losses, train_accs, test_losses, test_accs, fig_name="training_metrics.png"):
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, 'b', label='Training Loss')
    plt.plot(epochs, test_losses, 'r', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accs, 'b', label='Training Accuracy')
    plt.plot(epochs, test_accs, 'r', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(fig_name)
    print(f"Training metrics plot saved as {fig_name}")
    plt.show()

def plot_confusion_matrix(model, test_loader, device, num_classes=10, class_names=None, fig_name="confusion_matrix.png"):
    model.eval()
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            if device == torch.device('cuda'):
                with torch.amp.autocast('cuda'):
                    output = model(data)
            else:
                output = model(data)
            _, predicted = output.max(1)
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())

    cm = confusion_matrix(all_targets, all_preds)

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    plt.tight_layout()
    plt.savefig(fig_name)
    print(f"Confusion matrix plot saved as {fig_name}")
    plt.show()

    # Calculate and print class-wise accuracy
    print("\nClass-wise Accuracy:")
    for i in range(num_classes):
        true_positives = cm[i, i]
        total_in_class = np.sum(cm[i, :])
        accuracy = (true_positives / total_in_class) * 100 if total_in_class > 0 else 0
        print(f"  {class_names[i]}: {accuracy:.2f}%")


def denormalize_image(tensor, mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)):
    # Create a denormalize transform
    inv_normalize = transforms.Normalize(
        mean=[-m/s for m, s in zip(mean, std)],
        std=[1/s for s in std]
    )
    return inv_normalize(tensor)

def display_sample_predictions(model, test_dataset, device, num_samples=9, class_names=None, fig_name="sample_predictions.png"):
    model.eval()
    plt.figure(figsize=(num_samples * 2, 6))

    # Randomly select indices from the test dataset
    sample_indices = random.sample(range(len(test_dataset)), num_samples)

    images = []
    labels = []
    predictions = []

    with torch.no_grad():
        for i, idx in enumerate(sample_indices):
            image, label = test_dataset[idx]
            images.append(image)
            labels.append(label)

            # Add batch dimension and move to device
            input_image = image.unsqueeze(0).to(device)

            if device == torch.device('cuda'):
                with torch.amp.autocast('cuda'):
                    output = model(input_image)
            else:
                output = model(input_image)

            _, predicted = output.max(1)
            predictions.append(predicted.item())

    for i in range(num_samples):
        ax = plt.subplot(2, (num_samples + 1) // 2, i + 1)
        # Denormalize for display
        img_display = denormalize_image(images[i])
        img_display = img_display.permute(1, 2, 0) # Convert from CxHxW to HxWxC for matplotlib
        img_display = torch.clamp(img_display, 0, 1) # Clip values to [0,1] for display

        ax.imshow(img_display.cpu().numpy())
        true_label_name = class_names[labels[i]] if class_names else str(labels[i])
        pred_label_name = class_names[predictions[i]] if class_names else str(predictions[i])

        color = "green" if true_label_name == pred_label_name else "red"
        ax.set_title(f"True: {true_label_name}\nPred: {pred_label_name}", color=color, fontsize=10)
        ax.axis('off')

    plt.tight_layout()
    plt.savefig(fig_name)
    print(f"Sample predictions plot saved as {fig_name}")
    plt.show()


if __name__ == "__main__":
    fp32_num_epochs = 100 # Set epochs for FP32 training

    print("\n" + "="*50)
    print("           Training Full Precision (FP32) Model          ")
    print("="*50)

    model_fp32 = ResNet18().to(device)
    optimizer_fp32 = optim.AdamW(model_fp32.parameters(), lr=0.001, weight_decay=0.01)
    scheduler_fp32 = optim.lr_scheduler.CosineAnnealingLR(optimizer_fp32, T_max=fp32_num_epochs, eta_min=1e-6)
    scaler_fp32 = torch.amp.GradScaler() # Initialize GradScaler.

    # Train the model and get metric histories
    best_acc_fp32, train_losses, train_accs, test_losses, test_accs = train_model(
        model_instance=model_fp32,
        num_epochs=fp32_num_epochs,
        target_accuracy=95.0,
        model_type="float",
        optimizer_instance=optimizer_fp32,
        scheduler_instance=scheduler_fp32,
        scaler_instance=scaler_fp32,
        current_device=device
    )

    # Load the best FP32 model for final evaluation and visualization
    model_fp32_best = ResNet18().to(device)
    if os.path.exists('best_float_model.pth'):
        model_fp32_best.load_state_dict(torch.load('best_float_model.pth'))
        print("\nLoaded best_float_model.pth for final evaluation and visualization.")
    else:
        print("Warning: 'best_float_model.pth' not found. Using the last state of the trained FP32 model for evaluation.")
        model_fp32_best = model_fp32 # Use the last state if best model wasn't saved (e.g., due to early stopping before improvement)

    # Evaluate FP32 model for final metrics and confusion matrix data
    accuracy_fp32, _, all_preds_fp32, all_targets_fp32 = test_epoch(model_fp32_best, test_loader, criterion, device)
    size_fp32 = measure_model_size(model_fp32_best, "model_fp32.pth")
    inference_time_fp32 = measure_inference_time(model_fp32_best, test_loader, device)

    print(f"\nFP32 Model - Final Accuracy: {accuracy_fp32:.2f}% | Size: {size_fp32:.2f} MB | Inference Time: {inference_time_fp32:.2f} ms/sample")

    # --- Visualizations ---
    print("\n" + "="*50)
    print("           Generating Visualizations for FP32 Model          ")
    print("="*50)

    # 1. Plot Training/Validation Loss and Accuracy Curves
    plot_metrics(train_losses, train_accs, test_losses, test_accs, fig_name="fp32_training_curves.png")

    # 2. Plot Confusion Matrix and Class-wise Accuracy
    plot_confusion_matrix(model_fp32_best, test_loader, device, num_classes=10, class_names=cifar10_class_names, fig_name="fp32_confusion_matrix.png")

    # 3. Display Sample Predictions
    display_sample_predictions(model_fp32_best, test_dataset, device, num_samples=9, class_names=cifar10_class_names, fig_name="fp32_sample_predictions.png")

    print("\nFP32 training and visualization complete. Run ptq_model.py or qat_model.py next.")
